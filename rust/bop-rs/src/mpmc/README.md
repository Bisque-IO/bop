# MPMC Queue Wrapper

High-performance Multi-Producer Multi-Consumer (MPMC) queue implementation using moodycamel's concurrent queue library through BOP's C API.

## Overview

This module provides safe Rust wrappers around the moodycamel concurrent queue, one of the fastest lock-free queue implementations available. It offers both non-blocking and blocking variants with comprehensive safety guarantees.

## Features

- ‚ú® **Lock-Free**: Non-blocking operations for maximum performance
- üîí **Thread-Safe**: Multiple producers and consumers can operate concurrently
- üéØ **Token Optimization**: Producer/consumer tokens for better performance in high-frequency scenarios
- üì¶ **Bulk Operations**: Efficient batch enqueue/dequeue operations
- ‚è±Ô∏è **Blocking Variant**: Optional blocking operations with precise timeout support
- üõ°Ô∏è **Memory Safe**: RAII cleanup and proper resource management
- ‚ö° **Zero-Copy**: Minimal overhead abstractions over C++ implementation

## Quick Start

### Basic Usage

```rust
use bop_rs::mpmc::MpmcQueue;

// Create a new queue
let queue = MpmcQueue::new()?;

// Producer thread
if queue.try_enqueue(42) {
    println!("Item enqueued successfully");
}

// Consumer thread
if let Some(item) = queue.try_dequeue() {
    println!("Dequeued: {}", item);
}
```

### Token-Based Optimization

For threads that perform many operations, tokens provide better performance:

```rust
use bop_rs::mpmc::MpmcQueue;

let queue = MpmcQueue::new()?;

// Create tokens (one per thread for best performance)
let producer_token = queue.create_producer_token()?;
let consumer_token = queue.create_consumer_token()?;

// More efficient operations
for i in 0..1000 {
    producer_token.try_enqueue(i);
}

while let Some(item) = consumer_token.try_dequeue() {
    println!("Got: {}", item);
}
```

### Blocking Queue with Timeouts

```rust
use bop_rs::mpmc::BlockingMpmcQueue;
use std::time::Duration;

let queue = BlockingMpmcQueue::new()?;

// This will block until an item is available or timeout expires
match queue.dequeue_wait(Duration::from_millis(1000))? {
    Some(item) => println!("Received: {}", item),
    None => println!("Timed out"),
}
```

## Performance Characteristics

### Benchmarks

Based on typical workloads:

- **Basic Operations**: ~50M ops/sec (single producer/consumer)
- **Token Operations**: ~80M ops/sec (single producer/consumer)
- **Bulk Operations**: ~100M ops/sec (batch size 1000)
- **Multi-threaded**: Scales well up to number of CPU cores

### When to Use Tokens

Tokens provide performance benefits when:
- A thread performs many consecutive operations
- You have dedicated producer/consumer threads
- Latency is critical

Tokens have overhead for creation, so use them for long-lived workers.

### Bulk vs Individual Operations

Use bulk operations when:
- Processing batches of items
- Network I/O where you can batch sends/receives
- Want to amortize per-operation costs

Individual operations are better for:
- Low latency requirements
- Interactive applications
- When items arrive sporadically

## API Reference

### Core Types

#### `MpmcQueue`
Non-blocking multi-producer multi-consumer queue.

```rust
impl MpmcQueue {
    pub fn new() -> MpmcResult<Self>
    pub fn size_approx(&self) -> usize
    pub fn try_enqueue(&self, item: u64) -> bool
    pub fn try_dequeue(&self) -> Option<u64>
    pub fn try_enqueue_bulk(&self, items: &[u64]) -> bool
    pub fn try_dequeue_bulk(&self, buffer: &mut [u64]) -> usize
    pub fn create_producer_token(&self) -> MpmcResult<ProducerToken>
    pub fn create_consumer_token(&self) -> MpmcResult<ConsumerToken>
}
```

#### `BlockingMpmcQueue`
Blocking variant with timeout support.

```rust
impl BlockingMpmcQueue {
    pub fn new() -> MpmcResult<Self>
    pub fn dequeue_wait(&self, timeout: Duration) -> MpmcResult<Option<u64>>
    pub fn dequeue_bulk_wait(&self, buffer: &mut [u64], timeout: Duration) -> MpmcResult<usize>
    // ... plus all non-blocking methods
}
```

#### `ProducerToken<'a>` / `ConsumerToken<'a>`
Optimized tokens for high-frequency operations.

```rust
impl ProducerToken<'_> {
    pub fn try_enqueue(&self, item: u64) -> bool
    pub fn try_enqueue_bulk(&self, items: &[u64]) -> bool
}

impl ConsumerToken<'_> {
    pub fn try_dequeue(&self) -> Option<u64>
    pub fn try_dequeue_bulk(&self, buffer: &mut [u64]) -> usize
}
```

### Error Types

```rust
#[derive(Debug, Error)]
pub enum MpmcError {
    CreationFailed,
    ProducerTokenCreationFailed,
    ConsumerTokenCreationFailed,
    OperationFailed,
    InvalidTimeout,
}
```

## Usage Patterns

### 1. Work Queue Pattern

Distribute tasks among multiple workers:

```rust
use bop_rs::mpmc::MpmcQueue;
use std::sync::Arc;
use std::thread;

let work_queue = Arc::new(MpmcQueue::new()?);

// Add work items
for task_id in 0..1000 {
    work_queue.try_enqueue(task_id);
}

// Spawn workers
let workers: Vec<_> = (0..4).map(|worker_id| {
    let queue = work_queue.clone();
    thread::spawn(move || {
        let consumer_token = queue.create_consumer_token()?;
        while let Some(task) = consumer_token.try_dequeue() {
            // Process task
            process_work_item(task);
        }
    })
}).collect();
```

### 2. Event Streaming Pattern

Stream events with backpressure handling:

```rust
use bop_rs::mpmc::BlockingMpmcQueue;
use std::time::Duration;

let event_queue = BlockingMpmcQueue::new()?;

// Producer
thread::spawn(move || {
    loop {
        let event = generate_event();
        if !event_queue.try_enqueue(event) {
            // Handle backpressure
            thread::sleep(Duration::from_millis(1));
        }
    }
});

// Consumer
thread::spawn(move || {
    loop {
        match event_queue.dequeue_wait(Duration::from_secs(1))? {
            Some(event) => process_event(event),
            None => println!("No events in the last second"),
        }
    }
});
```

### 3. Pipeline Pattern

Chain multiple processing stages:

```rust
let stage1_to_2 = Arc::new(MpmcQueue::new()?);
let stage2_to_3 = Arc::new(MpmcQueue::new()?);

// Stage 1: Input processing
let queue1 = stage1_to_2.clone();
thread::spawn(move || {
    let token = queue1.create_producer_token()?;
    for input in input_stream {
        let processed = stage1_process(input);
        token.try_enqueue(processed);
    }
});

// Stage 2: Intermediate processing
let input_queue = stage1_to_2.clone();
let output_queue = stage2_to_3.clone();
thread::spawn(move || {
    let consumer = input_queue.create_consumer_token()?;
    let producer = output_queue.create_producer_token()?;
    
    while let Some(item) = consumer.try_dequeue() {
        let result = stage2_process(item);
        producer.try_enqueue(result);
    }
});
```

## Best Practices

### Performance Tips

1. **Use Tokens for High Frequency**: If a thread will do >100 operations, use tokens
2. **Batch Operations**: Use bulk methods when processing multiple items
3. **Avoid Spinning**: Use blocking queues or add backoff for empty queues
4. **Size Monitoring**: Use `size_approx()` to monitor queue health

### Memory Management

1. **Token Lifetimes**: Tokens must not outlive their parent queue
2. **Cleanup**: Resources are automatically cleaned up via RAII
3. **Thread Safety**: All operations are thread-safe, tokens are `Send` but not `Sync`

### Error Handling

```rust
use bop_rs::mpmc::{MpmcQueue, MpmcError};

match MpmcQueue::new() {
    Ok(queue) => {
        // Use queue
    }
    Err(MpmcError::CreationFailed) => {
        // Handle queue creation failure
        // This might indicate system resource exhaustion
    }
    Err(e) => {
        eprintln!("Unexpected error: {}", e);
    }
}
```

## Integration with Other BOP Components

### With Custom Allocator

The MPMC queue automatically uses BOP's high-performance allocator:

```rust
use bop_rs::allocator::BopAllocator;

#[global_allocator]
static GLOBAL: BopAllocator = BopAllocator;

// All MPMC operations now use the optimized allocator
let queue = MpmcQueue::new()?;
```

### With Networking

Combine with BOP's networking stack:

```rust
use bop_rs::{mpmc::MpmcQueue, usockets::HttpApp};

let message_queue = Arc::new(MpmcQueue::new()?);
let mut app = HttpApp::new()?;

let queue_clone = message_queue.clone();
app.post("/api/messages", move |mut res, req| {
    let message_id = generate_message_id();
    if queue_clone.try_enqueue(message_id) {
        res.end_str("Message queued", false)?;
    } else {
        res.status("503 Service Unavailable")?
           .end_str("Queue full", false)?;
    }
})?;
```

## Debugging and Monitoring

### Queue Health Monitoring

```rust
fn monitor_queue_health(queue: &MpmcQueue) {
    let size = queue.size_approx();
    
    if size > 10000 {
        warn!("Queue getting large: {} items", size);
    }
    
    if size > 100000 {
        error!("Queue critically full: {} items", size);
        // Consider implementing backpressure or alerting
    }
}
```

### Performance Profiling

```rust
use std::time::Instant;

let start = Instant::now();
let mut operations = 0;

// Perform operations
for i in 0..1000000 {
    if queue.try_enqueue(i) {
        operations += 1;
    }
}

let elapsed = start.elapsed();
let ops_per_sec = operations as f64 / elapsed.as_secs_f64();
println!("Performance: {:.0} ops/sec", ops_per_sec);
```

## Comparison with Alternatives

| Feature | MPMC Queue | std::mpsc | crossbeam-channel |
|---------|------------|-----------|-------------------|
| Lock-free | ‚úÖ | ‚ùå | ‚úÖ |
| Multiple producers | ‚úÖ | ‚ùå | ‚úÖ |
| Multiple consumers | ‚úÖ | ‚úÖ | ‚úÖ |
| Bulk operations | ‚úÖ | ‚ùå | ‚ùå |
| Token optimization | ‚úÖ | ‚ùå | ‚ùå |
| Blocking with timeout | ‚úÖ | ‚ùå | ‚úÖ |
| C++ performance | ‚úÖ | ‚ùå | ‚ùå |

## Limitations

- **Item Type**: Currently limited to `u64` items (can be extended for generic types)
- **Memory Usage**: May use more memory than simpler queues due to lock-free algorithms
- **Platform**: Requires BOP C++ library to be linked
- **Complexity**: More complex than simple mutex-based queues

## Future Enhancements

- **Generic Types**: Support for arbitrary `T: Send + 'static` types
- **Priority Queues**: Priority-based dequeuing
- **Persistent Queues**: Disk-backed queues for durability
- **Metrics Integration**: Built-in Prometheus metrics

## Examples

See the `examples/` directory for complete working examples:

- `mpmc_example.rs`: Comprehensive usage demonstrations
- `performance_benchmark.rs`: Performance testing utilities

## License

MIT OR Apache-2.0